{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import ortho_group\n",
    "import sklearn.linear_model as lin\n",
    "import time\n",
    "from mpc import *\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worse instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subspace_basis(t, d):\n",
    "    U = ortho_group.rvs(d)\n",
    "    return U[:t]\n",
    "\n",
    "# B is t x d orthogonal basis vectors, project it out of vector v\n",
    "def subspace_project(B, v):\n",
    "    for i in xrange(len(B)):\n",
    "        v = v - np.dot(v, B[i]) * B[i]\n",
    "    return v\n",
    "\n",
    "# scale covariance down\n",
    "def scaled_normal(d):\n",
    "    return np.random.normal(scale = 1.0 / np.sqrt(d), size = d)\n",
    "\n",
    "def top_vector_samples(U, n3, t):\n",
    "    d = len(U)\n",
    "    A1 = np.random.normal(scale = 1.0, size = (n3, d))\n",
    "    diagonal = np.zeros(d)\n",
    "    diagonal[:(t/2)] = np.sqrt(d) / np.sqrt(t)\n",
    "    diagonal[(t/2):t] = 1.0\n",
    "    basis_aligned = np.dot(U.T, np.dot(np.diag(diagonal), U))\n",
    "    return np.dot(A1, basis_aligned)\n",
    "\n",
    "# random n1 rows outside small subspace\n",
    "# basis of subspace, blown up to be quite large\n",
    "# other n2 random rows that are also large\n",
    "def worse_instance(d, t, n1, n2, n3):\n",
    "    U = ortho_group.rvs(d)\n",
    "    B = U[:t]\n",
    "    A1 = np.sqrt(2 * d) * top_vector_samples(U, n1, t)\n",
    "    A2 = np.asarray([subspace_project(B, scaled_normal(d)) for i in xrange(n2)]) # should be unit norm?\n",
    "    A3 = np.asarray([subspace_project(B, scaled_normal(d)) for i in xrange(n3)]) * d # should be norm about d\n",
    "    A = np.vstack((A1, A2, A3))\n",
    "    # np.random.shuffle(A)\n",
    "    return A\n",
    "\n",
    "def normalize(A):\n",
    "    (n, d) = np.shape(A)\n",
    "    B = np.zeros((n, d))\n",
    "    for i in xrange(n):\n",
    "        B[i] = A[i] / np.linalg.norm(A[i])\n",
    "    return B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tau decrease: hard instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = worse_instance(400, 4, 16, 6000, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree = 10 # degree of rational approximation\n",
    "jldirs = 7 # number of JL directions used\n",
    "niters = 25 # number of iterations of solver\n",
    "alpha = 1.0 # step size of solver\n",
    "\n",
    "coeffs = np.asarray(ratapprox(degree))\n",
    "reg = lin.Ridge(alpha=0.0, solver='lsqr', tol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A1 = worse_instance(400, 4, 16, 6000, 200)\n",
    "(w1, mvs1, taulist1) = mpc_ideal_niters_savetau(A1, 2000, alpha, niters, jldirs, coeffs)\n",
    "print len(taulist1) # if terminated early, make sure to change the plot length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A2 = worse_instance(400, 4, 16, 6000, 200)\n",
    "(w2, mvs2, taulist2) = mpc_ideal_niters_savetau(A2, 2000, alpha, niters, jldirs, coeffs)\n",
    "print len(taulist2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A3 = worse_instance(400, 4, 16, 6000, 200)\n",
    "(w3, mvs3, taulist3) = mpc_ideal_niters_savetau(A3, 2000, alpha, niters, jldirs, coeffs)\n",
    "print len(taulist3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.errorbar(x=np.arange(0, 26, 1), y=taulist1)\n",
    "plt.xticks(np.arange(0, 26, 5))\n",
    "plt.title(\"Weighted tau values (run 1)\")\n",
    "plt.xlabel(\"Iteration number\")\n",
    "plt.ylabel(\"Weighted tau\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.errorbar(x=np.arange(0, 26, 1), y=taulist2)\n",
    "plt.xticks(np.arange(0, 26, 5))\n",
    "plt.title(\"Weighted tau values (run 2)\")\n",
    "plt.xlabel(\"Iteration number\")\n",
    "plt.ylabel(\"Weighted tau\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.errorbar(x=np.arange(0, 26, 1), y=taulist3)\n",
    "plt.xticks(np.arange(0, 26, 5))\n",
    "plt.title(\"Weighted tau values (run 3)\")\n",
    "plt.xlabel(\"Iteration number\")\n",
    "plt.ylabel(\"Weighted tau\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decrease l2 norm squared with respect to d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_norm_noise(A, xtrue, stdev):\n",
    "    (n, d) = np.shape(A)\n",
    "    row_norms = np.asarray([np.linalg.norm(A[i]) for i in xrange(n)])\n",
    "    noise = np.dot(np.diag(row_norms), np.random.normal(scale = stdev, size = n))\n",
    "    return np.dot(A, xtrue) + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE for naive fits\n",
    "squared_errors_dexp = np.zeros((10, 15))\n",
    "for i in xrange(1, 11, 1):\n",
    "    print i\n",
    "    d = 50 * i\n",
    "    (t, n1, n2, n3) = (4, 16, 10 * d, d / 2)\n",
    "    A = worse_instance(d, t, n1, n2, n3)\n",
    "    for j in xrange(15):\n",
    "        xtrue = np.random.normal(size = d)\n",
    "        b = row_norm_noise(A, xtrue, 0.1)\n",
    "        x = reg.fit(A, b).coef_\n",
    "        squared_errors_dexp[i - 1][j] = (np.linalg.norm(xtrue - x) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree = 10 # degree of rational approximation\n",
    "jldirs = 7 # number of JL directions used\n",
    "niters = 20 # number of iterations of solver\n",
    "alpha = 1.0 # step size of solver\n",
    "\n",
    "coeffs = np.asarray(ratapprox(degree))\n",
    "reg = lin.Ridge(alpha=0.0, solver='lsqr', tol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE for MPC fits\n",
    "squared_errors_mpc_dexp = np.zeros((10, 15))\n",
    "for i in xrange(1, 11, 1):\n",
    "    print i\n",
    "    d = 50 * i\n",
    "    (t, n1, n2, n3) = (4, 16, 10 * d, d / 2)\n",
    "    A = worse_instance(d, t, n1, n2, n3)\n",
    "    (w, total_mv) = mpc_ideal_niters(A, 5 * d, alpha, niters, jldirs, coeffs)\n",
    "    for j in xrange(15):\n",
    "        xtrue = np.random.normal(size = d)\n",
    "        b = row_norm_noise(A, xtrue, 0.1)\n",
    "        x = reg.fit(WhalfA(A, w), np.sqrt(w) * b).coef_\n",
    "        squared_errors_mpc_dexp[i - 1][j] = (np.linalg.norm(xtrue - x) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means_squared_errors_dexp = np.asarray([np.mean(squared_errors_dexp[i]) for i in xrange(10)])\n",
    "means_squared_errors_dexp_mpc = np.asarray([np.mean(squared_errors_mpc_dexp[i]) for i in xrange(10)])\n",
    "stdevs_squared_errors_dexp = np.asarray([np.std(squared_errors_dexp[i]) for i in xrange(10)])\n",
    "stdevs_squared_errors_dexp_mpc = np.asarray([np.std(squared_errors_mpc_dexp[i]) for i in xrange(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.errorbar(x=np.arange(50, 550, 50), y=means_squared_errors_dexp, yerr=stdevs_squared_errors_dexp)\n",
    "plt.errorbar(x=np.arange(50, 550, 50), y=means_squared_errors_dexp_mpc, yerr=stdevs_squared_errors_dexp_mpc)\n",
    "plt.xticks(np.arange(50, 550, 50))\n",
    "plt.title(\"Mean squared errors, changing d\")\n",
    "plt.xlabel(\"Dimension d\")\n",
    "plt.ylabel(\"Mean squared error\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
